## 4. Méthodologie expérimentale

La démarche expérimentale suit un enchaînement rigoureux permettant d’évaluer l’apport d’ANFIS dans la prédiction du risque de crédit par rapport à deux références supervisées classiques. Les étapes décrites ci-dessous couvrent la compréhension du jeu de données, les traitements appliqués, la configuration des modèles, leur optimisation, les métriques retenues et les modalités de reproduction des expériences.

### 4.1 Jeu de données

Les expériences s’appuient sur le dataset « Default of Credit Card Clients » fourni par l’UCI Machine Learning Repository. Il rassemble 30 000 observations et 24 variables explicatives, auxquelles s’ajoute une variable cible binaire indiquant la présence d’un défaut de paiement. Les variables se regroupent en trois familles : i) démographiques (âge, genre, statut marital, niveau d’éducation), ii) comportementales (historique de remboursement mensuel, état des comptes sur les six derniers mois) et iii) financières (montants crédités, paiements, limites de carte). Le déséquilibre de classes est substantiel, avec une proportion de défauts située entre 22 % et 24 %, ce qui impose des précautions méthodologiques pour préserver la sensibilité du modèle face à la classe minoritaire. Les métadonnées de collecte n’indiquent pas de biais manifeste, mais la population cible est limitée à un échantillon taïwanais qu’il conviendra de garder à l’esprit lors de l’interprétation.

### 4.2 Prétraitement des données

Le pipeline de prétraitement débute par une vérification systématique des valeurs manquantes et des incohérences. Les enregistrements comportant des attributs critiques manquants sont supprimés, tandis que les valeurs isolées (outliers) sont détectées par analyse de z-scores sur les montants financiers et sont winsorisées lorsque cela est pertinent. Les variables numériques continues (montants, limites, paiements) sont normalisées via un MinMax scaler pour faciliter l’apprentissage de l’ANFIS et du SVM, très sensibles aux différences d’échelle. Les attributs catégoriels (par exemple l’éducation) sont encodés en one-hot, de manière à conserver l’absence d’ordonnancement implicite.

Une étape de sélection de variables est ajoutée pour contrer le fléau de la dimensionnalité, critique pour l’ANFIS. Des techniques comme l’élimination récursive de variables (RFE) ou l’analyse de corrélation permettront de retenir les 5 à 10 prédicteurs les plus pertinents pour ce modèle.

Le dataset est ensuite divisé en partitions d’entraînement et de test selon un ratio 80/20 avec stratification de la variable cible afin de reproduire le déséquilibre dans chaque sous-échantillon. Pour atténuer l’impact du déséquilibre durant l’entraînement, deux approches sont envisagées selon le modèle : i) suréchantillonnage synthétique de la classe minoritaire par SMOTE dans l’espace d’entraînement, ii) pondération inversement proportionnelle des classes dans les algorithmes prenant en charge des poids (Random Forest, SVM).

### 4.3 Modèles étudiés

**Random Forest (baseline).** Le modèle de référence repose sur une forêt aléatoire, choisie pour sa robustesse aux interactions non linéaires et sa tolérance aux variables corrélées. Les principaux hyperparamètres étudiés sont le nombre d’arbres (100 à 500), la profondeur maximale, la taille minimale des feuilles et le critère d’impureté (Gini vs. entropie). Cette baseline offre un point de comparaison interprétable vis-à-vis des méthodes neuro-fuzzy.

**Support Vector Machine.** Le SVM utilise un noyau RBF afin de capturer des frontières non linéaires dans l’espace des clients. Son efficacité dépend fortement de l’échelle des variables (d’où la normalisation précédente) et des hyperparamètres C (contrôle de la marge douce) et gamma (ampleur du noyau). Il sert de second comparateur, plus sensible aux configurations de déséquilibre mais performant sur des jeux de données de taille moyenne.

**ANFIS (Adaptive Neuro-Fuzzy Inference System).** Le modèle principal combine une architecture de type Takagi-Sugeno avec un apprentissage hybride. Les fonctions d’appartenance choisies sont de forme gaussienne ou généralisée bell pour assurer une transition douce entre les règles floues. Les règles sont générées à partir d’un clustering des observations (méthode de type subtractive clustering) afin de limiter le nombre de règles nécessaires. L’algorithme d’apprentissage suit un schéma hybride : estimation des paramètres des conclusions par moindres carrés conditionnels à la couche floue, suivie d’une mise à jour des paramètres des fonctions d’appartenance par descente de gradient. Cette combinaison est particulièrement adaptée au crédit scoring, car elle permet de capturer des interactions complexes tout en conservant un niveau de transparence sur les règles extraites.

### 4.4 Stratégie d’optimisation

Tous les modèles sont optimisés suivant un protocole identique pour garantir l’équité de la comparaison. Une validation croisée stratifiée à k plis (k = 5 par défaut, portée à 10 pour confirmer la stabilité) est mise en œuvre sur le jeu d’entraînement. La recherche d’hyperparamètres repose sur une combinaison de GridSearch pour les plages restreintes (ex. profondeur maximale de la Random Forest) et de Randomized Search pour explorer efficacement les hyperparamètres continus (C, gamma, paramètres des fonctions d’appartenance). Les mêmes splits de validation sont réutilisés pour chaque modèle afin de limiter la variance introduite par la partition et de favoriser une comparaison rigoureuse.

### 4.5 Métriques d’évaluation

Le diagnostic de performance mobilise plusieurs indicateurs complémentaires. L’accuracy permet de situer les performances globales mais n’est pas suffisante en contexte déséquilibré. Le F1-score est privilégié pour synthétiser la précision et le rappel sur la classe défaut. La courbe ROC et son aire (AUC-ROC) quantifient la capacité discriminante du modèle indépendamment d’un seuil donné. Chaque modèle produit également une matrice de confusion sur l’ensemble de test pour détailler les erreurs de classification. Enfin, le rappel (sensibilité) de la classe défaut est présenté explicitement, car il constitue la priorité métier : manquer un client risqué est plus coûteux que faussement alerter sur un client sain.

Enfin, la significativité statistique des écarts de performance sera vérifiée (test de Wilcoxon ou t-test apparié) pour confirmer la supériorité éventuelle d'un modèle. Une évaluation qualitative de l'interprétabilité complétera l'analyse, en vérifiant la cohérence métier des règles floues générées par l'ANFIS.

### 4.6 Explicabilité et analyse des contributions (SHAP)

Pour renforcer l'analyse d'interprétabilité et quantifier objectivement l'importance des variables, les valeurs SHAP (SHapley Additive exPlanations) seront calculées pour chaque modèle. Cette approche, fondée sur la théorie des jeux coopératifs, permet d'attribuer à chaque variable une contribution marginale à la prédiction, garantissant ainsi une mesure cohérente et équitable de l'influence de chaque attribut. Contrairement aux méthodes classiques d'importance des variables (ex. feature importance de Random Forest), SHAP offre une interprétation locale (contribution à une prédiction individuelle) et globale (importance agrégée sur l'ensemble du jeu de données), tout en étant agnostique au type de modèle.

Trois analyses principales seront conduites : i) les graphiques de résumé (summary plots) montrant l'importance globale et la distribution des contributions pour chaque variable, ii) les graphiques de force (force plots) illustrant la décomposition additive des prédictions individuelles, permettant de comprendre pourquoi un client particulier est classé comme risqué ou non, et iii) les graphiques de dépendance (dependence plots) révélant les interactions non linéaires entre variables. Pour l'ANFIS, les valeurs SHAP permettront de valider quantitativement la cohérence des règles floues extraites : si une règle attribue un poids élevé à une variable (ex. « PAY_0 = Retard »), les SHAP values doivent confirmer l'importance de cette variable dans les prédictions correspondantes.

Cette double validation — règles floues qualitatives (ANFIS) et contributions quantitatives (SHAP) — renforce la crédibilité de l'analyse d'interprétabilité et offre une comparaison objective entre les trois modèles (Random Forest, SVM, ANFIS). Les résultats SHAP seront présentés sous forme de visualisations interactives et de tableaux synthétiques, facilitant l'appropriation par les experts métier du domaine du crédit.

### 4.7 Protocole expérimental et reproductibilité

L'ensemble du pipeline est implémenté en Python 3.11. Les bibliothèques principales sont pandas et NumPy pour la manipulation des données, scikit-learn pour les modèles Random Forest et SVM ainsi que pour les utilitaires de prétraitement, scikit-fuzzy (ou une implémentation ANFIS compatible) pour la couche neuro-fuzzy, imbalanced-learn pour SMOTE, et SHAP pour l'analyse d'explicabilité. Chaque étape est encapsulée dans des scripts reproductibles versionnés sous Git. Les graines aléatoires sont fixées (seed = 42) pour la partition, l'initialisation des modèles et l'algorithme SMOTE, de manière à assurer la reproductibilité des résultats. Les sorties principales comprennent des tableaux comparant les métriques, des courbes ROC, des graphiques de sensibilité par modèle, des visualisations SHAP (summary plots, force plots, dependence plots) et une analyse d'erreur textuelle. L'ensemble de ces éléments alimente directement la section de résultats ainsi que l'interprétation de la portée opérationnelle de l'ANFIS.

L’organisation précédemment décrite garantit une méthodologie cohérente et transparente, apte à soutenir des conclusions solides sur l’intérêt de l’ANFIS pour la prédiction du risque de crédit.
